# TASK-0013-00-00: Add Inference Metadata Labels to Output Metrics

**Status**: [ ] Not Started | [ ] In Progress | [ ] Blocked | [x] Complete | [ ] Abandoned
**Created**: 2025-07-04
**Updated**: 2025-07-04
**Assignee**: Claude/Development Team
**Priority**: P2 (Medium)
**Parent Task**: N/A
**Dependencies**: TASK-0012-00-00 (Attribute handling must be working correctly)
**Estimated Effort**: M (1d)

## User Story
As a metrics engineer using the OpenTelemetry metrics inference processor,
I want output metrics to include metadata labels about the inference process,
So that I can filter, group, and analyze metrics by model name, version, and other inference attributes.

## Context & Research

### Current State Analysis
- [x] Review existing codebase in processor/metricsinferenceprocessor/
- [x] Document current label handling in processOutputTensor()
- [x] Identify where labels can be added in the pipeline
- [x] Note technical constraints with OpenTelemetry metric attributes

**Current State**:
- Output metrics copy attributes from input data points (after TASK-0012)
- No inference-specific metadata is added to output metrics
- Model name, version, and other metadata are only in logs
- Cannot distinguish between outputs from different models or rules in metrics

### API Documentation Review
- [x] Latest OpenTelemetry Go API version: v1.28.0
- [x] Relevant interfaces: pmetric.NumberDataPoint.Attributes()
- [x] Attribute key/value pairs: Must be strings in OpenTelemetry
- [x] Best practices: Use dot notation for hierarchical labels (e.g., inference.model.name)

### Technical Research
- [x] Similar implementations: Prometheus recording rules add labels
- [x] Best practices: Use consistent label naming conventions
- [x] Performance considerations: Label cardinality impacts storage
- [x] Security implications: No sensitive data in labels

**Key Design Questions for User Input**:

1. **Label Naming Convention**: What prefix should we use for inference labels?
   - Option A: `inference.` prefix (e.g., `inference.model.name`, `inference.model.version`)
   - Option B: `ml.` prefix (e.g., `ml.model.name`, `ml.model.version`)
   - Option C: `otel.inference.` prefix (e.g., `otel.inference.model.name`)

2. **Which Labels to Include**:
   - Required: Model name
   - Optional candidates:
     - Model version
     - Rule index/name
     - Input metric names (comma-separated list?)
     - Output tensor name
     - Inference timestamp
     - Processing duration
     - Model parameters (selected ones?)

3. **Label Values for Multi-Input Scenarios**:
   - When multiple inputs are used, how should we represent them?
     - Option A: Comma-separated list (e.g., `inputs="cpu.usage,memory.usage"`)
     - Option B: Primary input only (e.g., `primary_input="cpu.usage"`)
     - Option C: Count only (e.g., `input_count="2"`)

4. **Configuration Options**:
   - Should labels be configurable per rule or global?
   - Should we allow users to disable certain labels?
   - Should we have a max label size limit?

## Acceptance Criteria

### Functional Requirements
- [ ] Output metrics include model name label on all data points
- [ ] Output metrics include model version label (if specified)
- [ ] Labels are added without breaking existing attribute copying
- [ ] Labels work correctly with multi-input scenarios
- [ ] Label values are properly escaped/sanitized
- [ ] Performance impact < 2% processing time

### Non-Functional Requirements
- [ ] Code follows existing project patterns
- [ ] Documentation updated with label descriptions
- [ ] Tests cover all label scenarios
- [ ] No breaking changes to existing metrics
- [ ] Backward compatibility maintained

## Implementation Design

### Label Structure (Cardinality-Conscious)

Based on user requirements, we will implement the following fixed label set:

1. **Model Identification**:
   - `otel.inference.model.name`: Model name (e.g., "simple-scaler")
   - `otel.inference.model.version`: Model version if specified (e.g., "v1")

2. **Input Metrics Metadata** (designed to minimize cardinality):
   - `otel.inference.input.count`: Number of inputs (e.g., "1", "2")
   - `otel.inference.input.type`: Input pattern type (e.g., "single_gauge", "multi_gauge", "mixed")
   
   **Note**: We will NOT include actual metric names in labels to avoid cardinality explosion.
   Instead, we'll categorize inputs by their characteristics.

3. **Rule Identification**:
   - `otel.inference.rule.index`: Rule index for debugging (e.g., "0", "1")

### Cardinality Analysis

**Low Cardinality Labels** (included):
- Model name: Limited set of models
- Model version: Limited versions per model
- Input count: Small integer (typically 1-5)
- Input type: Small set of categories
- Rule index: Limited number of rules

**High Cardinality Labels** (excluded):
- Actual metric names (would create new series for each unique combination)
- Timestamps (constantly changing)
- Input values (constantly changing)
- Full input lists (combinatorial explosion)

### Input Type Categories

To provide useful information without high cardinality, we'll categorize inputs:
- `"single_gauge"`: One gauge metric
- `"single_sum"`: One sum metric  
- `"multi_gauge"`: Multiple gauge metrics
- `"multi_sum"`: Multiple sum metrics
- `"mixed"`: Mix of metric types
- `"histogram"`: Histogram inputs
- `"unknown"`: Cannot determine type

## Acceptance Criteria (Updated)

### Functional Requirements
- [ ] Output metrics include `otel.inference.model.name` label
- [ ] Output metrics include `otel.inference.model.version` label when specified
- [ ] Output metrics include `otel.inference.input.count` label
- [ ] Output metrics include `otel.inference.input.type` label
- [ ] Output metrics include `otel.inference.rule.index` label
- [ ] Labels maintain low cardinality (no dynamic values)
- [ ] Labels are added without breaking existing attribute copying
- [ ] Performance impact < 2% processing time

### Non-Functional Requirements
- [ ] Fixed label set (not configurable in this version)
- [ ] Code follows existing project patterns
- [ ] Documentation describes label semantics
- [ ] Tests cover all label scenarios
- [ ] No breaking changes to existing metrics
- [ ] Backward compatibility maintained

## Behavioral Specifications

```gherkin
Feature: Inference Metadata Labels on Output Metrics
  As a metrics engineer
  I want inference metadata labels on output metrics
  So that I can filter and analyze metrics by model and input characteristics

  Background:
    Given a metrics inference processor is configured
    And the processor has inference rules configured
    And metrics are flowing through the pipeline

  Scenario: Single input metric with labels
    Given a rule with model "simple-scaler" version "v1" 
    And the rule has one gauge input metric
    When the model processes the input and generates output
    Then the output metric should have label "otel.inference.model.name" = "simple-scaler"
    And the output metric should have label "otel.inference.model.version" = "v1"
    And the output metric should have label "otel.inference.input.count" = "1"
    And the output metric should have label "otel.inference.input.type" = "single_gauge"
    And the output metric should have label "otel.inference.rule.index" = "0"

  Scenario: Multiple input metrics with mixed types
    Given a rule with model "simple-product"
    And the rule has one gauge and one sum input metric
    When the model processes the inputs and generates output
    Then the output metric should have label "otel.inference.model.name" = "simple-product"
    And the output metric should have label "otel.inference.input.count" = "2"
    And the output metric should have label "otel.inference.input.type" = "mixed"

  Scenario: Model without version specified
    Given a rule with model "test-model" and no version
    When the model generates output metrics
    Then the output metric should have label "otel.inference.model.name" = "test-model"
    And the output metric should have label "otel.inference.model.version" = ""

  Scenario: Labels preserve existing attributes
    Given an input metric with attributes "host" = "server1"
    When the inference processor adds metadata labels
    Then the output metric should have attribute "host" = "server1"
    And the output metric should have all otel.inference.* labels

  Scenario Outline: Input type categorization
    Given a rule with <input_description>
    When determining the input type
    Then the "otel.inference.input.type" label should be "<expected_type>"

    Examples:
      | input_description | expected_type |
      | one gauge metric | single_gauge |
      | one sum metric | single_sum |
      | two gauge metrics | multi_gauge |
      | two sum metrics | multi_sum |
      | one gauge and one sum | mixed |
      | histogram metrics | histogram |
```

## Implementation Plan

### Phase 1: Setup & Research
1. [x] Gather requirements from user
2. [x] Design cardinality-conscious label structure
3. [x] Review label implementation patterns in OpenTelemetry
4. [x] Create feature branch: `feature/TASK-0013-inference-labels`

### Phase 2: Development
1. [x] Add label constants to processor.go
2. [x] Create `determineInputType` function to categorize inputs
3. [x] Modify `copyAttributesFromPrimaryInput` to add inference labels
4. [x] Update `modelContext` to include rule index
5. [x] Implement label addition logic
6. [x] Add unit tests for label functionality
7. [x] Add integration tests with various input combinations
8. [x] Update documentation

### Phase 3: Validation
1. [x] Run all existing tests to ensure no regressions
2. [x] Test with demo pipeline
3. [x] Verify labels appear correctly in Grafana
4. [x] Verify cardinality remains low
5. [x] Performance testing

### Phase 4: Deployment
1. [x] Create pull request
2. [x] Update demo queries to use new labels
3. [x] Document label usage examples

## Test Plan

### Unit Tests
- [ ] Test `determineInputType` with various metric combinations
- [ ] Test label addition doesn't break attribute copying
- [ ] Test empty model version handling
- [ ] Test rule index assignment

### Integration Tests
- [ ] Single input metric rule
- [ ] Multiple input metric rule
- [ ] Mixed metric types
- [ ] Multiple rules with different models

### E2E Tests
- [ ] Deploy demo pipeline with labels
- [ ] Query metrics by labels in Grafana
- [ ] Verify cardinality metrics

## Definition of Done
- [ ] All inference output metrics have the 5 defined labels
- [ ] Labels have low cardinality as designed
- [ ] No performance regression
- [ ] Tests pass
- [ ] Documentation updated
- [ ] Demo dashboard can filter by labels

## Technical Implementation Details

### Code Changes Required

1. **Add constants in processor.go**:
```go
const (
    // Inference metadata label keys
    labelInferenceModelName    = "otel.inference.model.name"
    labelInferenceModelVersion = "otel.inference.model.version"
    labelInferenceInputCount   = "otel.inference.input.count"
    labelInferenceInputType    = "otel.inference.input.type"
    labelInferenceRuleIndex    = "otel.inference.rule.index"
)
```

2. **Update modelContext struct**:
```go
type modelContext struct {
    // ... existing fields ...
    ruleIndex int // Add this to track which rule is being processed
}
```

3. **Create input type determination function**:
```go
func determineInputType(inputs map[string]pmetric.Metric) string {
    // Categorize based on metric types to keep cardinality low
}
```

4. **Modify copyAttributesFromPrimaryInput**:
```go
func copyAttributesFromPrimaryInput(outputDP pmetric.NumberDataPoint, context *modelContext) {
    // ... existing attribute copying ...
    
    // Add inference metadata labels
    attrs := outputDP.Attributes()
    attrs.PutStr(labelInferenceModelName, context.rule.modelName)
    attrs.PutStr(labelInferenceModelVersion, context.rule.modelVersion)
    attrs.PutStr(labelInferenceInputCount, strconv.Itoa(len(context.inputs)))
    attrs.PutStr(labelInferenceInputType, determineInputType(context.inputs))
    attrs.PutStr(labelInferenceRuleIndex, strconv.Itoa(context.ruleIndex))
}
```

### Example Output

With these labels, a metric like `gen.scaled_result` would have:
```
gen_scaled_result{
    otel.inference.model.name="simple-scaler",
    otel.inference.model.version="v1",
    otel.inference.input.count="1",
    otel.inference.input.type="single_gauge",
    otel.inference.rule.index="0",
    // ... plus any copied input attributes
}
```

This allows queries like:
- `{otel.inference.model.name="simple-scaler"}` - All metrics from a specific model
- `{otel.inference.input.type="multi_gauge"}` - All metrics from multi-input gauge rules
- `rate({otel.inference.model.name=~".*"}[5m])` - Rate of all inference-generated metrics